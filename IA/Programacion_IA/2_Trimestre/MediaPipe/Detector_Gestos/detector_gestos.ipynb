{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2 as cv\n",
    "\n",
    "def get_distance(p1,p2):\n",
    "    return math.sqrt(((p2[0]-p1[0])**2+(p2[1]-p1[1])**2)+(p2[2]-p1[2])**2)\n",
    "\n",
    "def checkPiedraPapelTijera(image,landmarks,x,y):\n",
    "        if isHigher(8,6,landmarks) and isHigher(12,10,landmarks) and isHigher(16,14,landmarks) and isHigher(20,18,landmarks):\n",
    "            cv.rectangle(image, x, y, (0, 255, 0), 5)\n",
    "            cv.putText(image, \"PIEDRA\", x,  cv.FONT_HERSHEY_SIMPLEX, 2, (0,255,0),2)\n",
    "            return\n",
    "        elif isHigher(6,8,landmarks) and isHigher(10,12,landmarks) and isHigher(14,16,landmarks) and isHigher(18,20,landmarks):\n",
    "            cv.rectangle(image, x, y, (255, 0, 0), 5)\n",
    "            cv.putText(image, \"PAPEL\", x,  cv.FONT_HERSHEY_SIMPLEX, 2, (255,0,0),2)\n",
    "            return\n",
    "        elif isHigher(7,8,landmarks) and isHigher(11,12,landmarks) and isHigher(16,14,landmarks) and isHigher(20,18,landmarks):\n",
    "            cv.rectangle(image, x, y, (0, 0, 255), 5)\n",
    "            cv.putText(image, \"TIJERA\", x,  cv.FONT_HERSHEY_SIMPLEX, 2, (0,0,255),2)\n",
    "            return\n",
    "\n",
    "def isHigher(a,b,landmarks):\n",
    "    return get_distance(landmarks[0],landmarks[a]) < get_distance(landmarks[0],landmarks[b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import mediapipe as mp\n",
    "import cv2 as cv\n",
    "\n",
    "video = cv.VideoCapture(0)\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "\n",
    "    while(True):\n",
    "        ret, frame = video.read()\n",
    "        h, w, c = frame.shape\n",
    "        if ret == True:\n",
    "            x_max = 0\n",
    "            y_max = 0\n",
    "            x_min = w\n",
    "            y_min = h\n",
    "            frame = cv.flip(frame, 1)\n",
    "            cv.imshow(\"Salida\", frame)\n",
    "\n",
    "            # Flip the image horizontally for a later selfie-view display\n",
    "            image = cv.cvtColor(cv.flip(frame, 1), cv.COLOR_BGR2RGB)\n",
    "            # To improve performance, optionally mark the image as not writeable to\n",
    "            # pass by reference.\n",
    "            image.flags.writeable = False\n",
    "            # Process the image and find hand landmarks\n",
    "            results = hands.process(image)\n",
    "\n",
    "            # Draw the hand landmarks on the image\n",
    "            image.flags.writeable = True\n",
    "            image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                    points=[]\n",
    "                    for point in hand_landmarks.landmark:\n",
    "                        x, y = int(point.x * w), int(point.y * h)\n",
    "                        points.append((point.x,point.y,point.z))\n",
    "                        if x > x_max:\n",
    "                            x_max = x\n",
    "                        if x < x_min:\n",
    "                            x_min = x\n",
    "                        if y > y_max:\n",
    "                            y_max = y\n",
    "                        if y < y_min:\n",
    "                            y_min = y\n",
    "                    cv.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 5)\n",
    "                res = checkPiedraPapelTijera(image,points)\n",
    "                if res == \"PIEDRA\":\n",
    "                    #cv.putText(image, \"Prueba de texto\", (10, 300),  cv.FONT_HERSHEY_SIMPLEX, 10, (0,255,0),12)\n",
    "                    None\n",
    "            cv.imshow('MediaPipe Hands', image)\n",
    "        if ret == False:\n",
    "            video.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "        if cv.waitKey(10) & 0xFF == 27: break\n",
    "\n",
    "video.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown We implemented some functions to visualize the hand landmark detection results. <br/> Run the following cell to activate the functions.\n",
    "\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np\n",
    "\n",
    "MARGIN = 10  # pixels\n",
    "FONT_SIZE = 1\n",
    "FONT_THICKNESS = 1\n",
    "HANDEDNESS_TEXT_COLOR = (88, 205, 54) # vibrant green\n",
    "\n",
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "  hand_landmarks_list = detection_result.hand_landmarks\n",
    "  handedness_list = detection_result.handedness\n",
    "  annotated_image = np.copy(rgb_image)\n",
    "\n",
    "  # Loop through the detected hands to visualize.\n",
    "  for idx in range(len(hand_landmarks_list)):\n",
    "    hand_landmarks = hand_landmarks_list[idx]\n",
    "    handedness = handedness_list[idx]\n",
    "\n",
    "    # Draw the hand landmarks.\n",
    "    hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "    hand_landmarks_proto.landmark.extend([\n",
    "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in hand_landmarks\n",
    "    ])\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "      annotated_image,\n",
    "      hand_landmarks_proto,\n",
    "      solutions.hands.HAND_CONNECTIONS,\n",
    "      solutions.drawing_styles.get_default_hand_landmarks_style(),\n",
    "      solutions.drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "    # Get the top left corner of the detected hand's bounding box.\n",
    "    height, width, _ = annotated_image.shape\n",
    "    x_coordinates = [landmark.x for landmark in hand_landmarks]\n",
    "    y_coordinates = [landmark.y for landmark in hand_landmarks]\n",
    "    text_x = int(min(x_coordinates) * width)\n",
    "    text_y = int(min(y_coordinates) * height) - MARGIN\n",
    "\n",
    "    # Draw handedness (left or right hand) on the image.\n",
    "\n",
    "  return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import pathlib\n",
    "\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "HandLandmarker = mp.tasks.vision.HandLandmarker\n",
    "HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "path=str(pathlib.Path().resolve())+\"/\"\n",
    "\n",
    "options = HandLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=path+\"hand_landmarker.task\"),\n",
    "    running_mode=VisionRunningMode.VIDEO,\n",
    "    num_hands=int(1e5),\n",
    "    min_hand_detection_confidence=0.3,\n",
    "    min_hand_presence_confidence=0.3,\n",
    "    min_tracking_confidence=0.3)\n",
    "\n",
    "\n",
    "with HandLandmarker.create_from_options(options) as landmarker:\n",
    "\n",
    "  t = time.time()\n",
    "  video = cv.VideoCapture(0)\n",
    "\n",
    "  while(True):\n",
    "\n",
    "    ret, frame = video.read()\n",
    "    h, w, c = frame.shape\n",
    "\n",
    "    if ret == True:\n",
    "\n",
    "      mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "\n",
    "      hand_landmarker_result = landmarker.detect_for_video(mp_image,int(round((time.time())*1000)))\n",
    "\n",
    "      # Usa draw_landmarks para dibujar las landmarks y las conexiones en la imagen\n",
    "      annotated_image=draw_landmarks_on_image(mp_image.numpy_view(), hand_landmarker_result)\n",
    "      for landmark in hand_landmarker_result.hand_landmarks:\n",
    "        for hands in hand_landmarker_result.hand_landmarks:\n",
    "            x_max = 0\n",
    "            y_max = 0\n",
    "            x_min = w\n",
    "            y_min = h\n",
    "            points=[]\n",
    "            for point in hands:\n",
    "                x, y = int(point.x * w), int(point.y * h)\n",
    "                points.append((point.x,point.y,point.z))\n",
    "                if x > x_max:\n",
    "                    x_max = x\n",
    "                if x < x_min:\n",
    "                    x_min = x\n",
    "                if y > y_max:\n",
    "                    y_max = y\n",
    "                if y < y_min:\n",
    "                    y_min = y\n",
    "        #cv.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 5)\n",
    "            checkPiedraPapelTijera(annotated_image,points,(x_min,y_min),(x_max,y_max))\n",
    "         \n",
    "\n",
    "      # Muestra la imagen con las landmarks\n",
    "      cv.imshow(\"Prueba\",annotated_image)\n",
    "    if ret == False:\n",
    "        video.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "    if cv.waitKey(10) & 0xFF == 27: break\n",
    "\n",
    "video.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
