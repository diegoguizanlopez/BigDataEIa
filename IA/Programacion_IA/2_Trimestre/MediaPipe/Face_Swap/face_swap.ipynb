{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -y conda-forge::dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "path = str(Path().resolve())+\"/Images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pImg1 = path + \"Walter.jpg\"\n",
    "pImg2 = path + \"Trump.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de las imagenes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread(pImg1)\n",
    "img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "mask = np.zeros_like(img_gray)\n",
    "\n",
    "img2 = cv.imread(pImg2)\n",
    "img2_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "img2 = cv.cvtColor(img2, cv.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos las dos imagenes con las que vamos a generar en su escala RGB para ver su estado actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].imshow(img)\n",
    "axs[1].imshow(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora con el archivo data_set importamos la constante TRIANGLE_SET que es la triangulación de la cara añadido por mi parte ojos y boca a mayores\n",
    "- Recogemos cada 3 valores de la lista\n",
    "- Lo convertimos en una tupla de 3 valores que representan las triangulaciones cada una con su unión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe.python.solutions import drawing_utils as mp_drawing\n",
    "import mediapipe.python.solutions.face_mesh as mp_faces\n",
    "from mediapipe.python.solutions import drawing_styles\n",
    "import data_set as dts\n",
    "\n",
    "listX=dts.TRIANGLE_SET\n",
    "lista = [listX[i:i+3] for i in range(0, len(listX), 3)]\n",
    "lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos una prueba para ver el comportamiento de los puntos rojos en la imagen de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import isin\n",
    "import numpy as np\n",
    "\n",
    "landmarkListImg1=[]\n",
    "with mp_faces.FaceMesh() as faces:\n",
    "    results = faces.process(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        landmarkListImg1 = [x for x in face_landmarks.landmark]\n",
    "\n",
    "with mp_faces.FaceMesh() as faces:\n",
    "    results = faces.process(cv.cvtColor(img2, cv.COLOR_BGR2RGB))\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        landmarkListImg2 = [x for x in face_landmarks.landmark]\n",
    "\n",
    "height, width = img.shape[:2]\n",
    "img_m = img.copy()\n",
    "triangulosImg1Marks={}\n",
    "for valor in lista:\n",
    "    for tupla in valor:\n",
    "        x1,y1=landmarkListImg1[tupla[0]].x*width,landmarkListImg1[tupla[0]].y*height\n",
    "        x2,y2=landmarkListImg1[tupla[1]].x*width,landmarkListImg1[tupla[1]].y*height\n",
    "        cv.line(img_m, (int(x1),int(y1)), (int(x2),int(y2)), (255,0,0), 1)\n",
    "        triangulosImg1Marks[tupla[0]]=[x1,y1]\n",
    "        triangulosImg1Marks[tupla[0]]=[x2,y2]\n",
    "\n",
    "height, width = img2.shape[:2]\n",
    "img2_m = img2.copy()\n",
    "triangulosImg2Marks={}\n",
    "for valor in lista:\n",
    "    for tupla in valor:\n",
    "        x1,y1=landmarkListImg2[tupla[0]].x*width,landmarkListImg2[tupla[0]].y*height\n",
    "        x2,y2=landmarkListImg2[tupla[1]].x*width,landmarkListImg2[tupla[1]].y*height\n",
    "        cv.line(img2_m, (int(x1),int(y1)), (int(x2),int(y2)), 255)\n",
    "        triangulosImg2Marks[tupla[0]]=[x1,y1]\n",
    "        triangulosImg2Marks[tupla[0]]=[x2,y2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos las triangulaciones de la cara de color rojo vemos que los recoge sin problema si son reconocibles en la imagen\n",
    "\n",
    "<span style=\"color:red\">SI LA IMAGEN NO ES RECONOCIDA AQUÍ NO VA EJECUTAR EL RESTO DEL RECONOCIMIENTO</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].imshow(img_m)\n",
    "axs[1].imshow(img2_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formateamos la lista que pasa de:\n",
    "- <span style=\"color:yellow\">De un array de 3 x 2 de valores de las uniones del triangulo</span>\n",
    "- <span style=\"color:green\">A un solo array de 1 x 3 de valores que representa directamente la triangulación</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangles=[]\n",
    "for t in lista:\n",
    "    pt1 = (t[0][0], t[0][1])\n",
    "    pt2 = (t[1][0], t[1][1])\n",
    "    pt3 = (t[2][0], t[2][1])\n",
    "    value = list(set([pt1[0],pt1[1],pt2[0],pt2[1],pt3[0],pt3[1]]))\n",
    "    triangles.append(value)\n",
    "print(triangles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comienzo de práctica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(pImg1)\n",
    "img2 = cv.imread(pImg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recogida de puntos inicialies de las caras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Configura la detección facial de MediaPipe\n",
    "with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5) as face_mesh:\n",
    "    \"\"\"Le indicamos que va ser una imagen estática, ya que los puntos los sacamos de la misma imagen, si fuera un video no indicabamos este apartado\n",
    "    \"\"\"\n",
    "\n",
    "    # Procesa la imagen 1\n",
    "    results = face_mesh.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Procesamos cada uno de los puntos de la imagen, multiplicando su X e Y por su ancho y largo, recordatorio que el X e Y están cambiados en OpenCV\n",
    "            landmarks_points = [(int(landmark.x * img.shape[1]), int(landmark.y * img.shape[0])) for landmark in face_landmarks.landmark]\n",
    "\n",
    "    # Procesa la imagen 2\n",
    "    results = face_mesh.process(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Mismo que la anterior imagen\n",
    "            landmarks_points2 = [(int(landmark.x * img2.shape[1]), int(landmark.y * img2.shape[0])) for landmark in face_landmarks.landmark]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recogida de triángulos de la cara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_face(imagen1,imagen2,land1,land2):\n",
    "    \"\"\"Devuelve la cara extraida y adaptada a la imagen que se le va hacer el acople\n",
    "\n",
    "    Args:\n",
    "        imagen1 (Array Object Np.Int(X)): Imagen donde vamos a extraer la cara de ahí\n",
    "        imagen2 (Array Object Np.Int(X)): Imagen 2 la cual recogeremos la posición de sus puntos y la usaremos para adaptar la imagen1\n",
    "        land1 (Array Tuple (X,Y)): LandmarkPoints de la primera Imagen\n",
    "        land2 (Array Tuple (X,Y)): LandmarkPoints de la segunda imagen\n",
    "\n",
    "    Returns:\n",
    "        Array Object Np.Int(X): Nueva imagen con solo la cara adaptados los puntos a la posición de la imagen\n",
    "    \"\"\"\n",
    "\n",
    "    # Array de la unión de los triangulos\n",
    "    global triangles\n",
    "\n",
    "    # Transformamos la imagen donde vamos a sacar la cara a escala de gris, \n",
    "    # Creamos un np.array basado en la imagen de grises y otra de la imagen que tenemos que adaptar la forma de la imagen\n",
    "    img_gray = cv2.cvtColor(imagen1, cv2.COLOR_BGR2GRAY)\n",
    "    lines_space_mask = np.zeros_like(img_gray)\n",
    "    img2_new_face = np.zeros_like(imagen2)\n",
    "    \n",
    "    triangles = np.array(triangles)\n",
    "\n",
    "    # region Función Calculada\n",
    "    def triangle_f(triangle_index):\n",
    "        \"\"\"Función definida para ejecutar de manera recursiva manejada por Numpy por su capa de C para optimización\n",
    "\n",
    "        Args:\n",
    "            triangle_index (Array Tuple (X1,X2,X3)): Cada uno de los indices de los triangulos\n",
    "        \"\"\"\n",
    "        # region Imagen 1 Tratamiento\n",
    "        # Sacamos los landmarks de la imagen actual y lo convertimos a un np.array de int32 ya que openCV no permite floats para el manejo de acciones\n",
    "        tr1_pts = [land1[idx] for idx in triangle_index]\n",
    "        triangle1 = np.array(tr1_pts, np.int32)\n",
    "        \n",
    "        # boundingRect devuelve un conjunto de 4 parametros la coordenada x,y y el width y height del array\n",
    "        rect1 = cv2.boundingRect(triangle1)\n",
    "        x, y, w, h = rect1\n",
    "\n",
    "        # Sacamos el triangulo que coorresponde a la posición y hasta el height correspondiente y viceversa con x\n",
    "        # Recordemos que openCV maneja X e Y al revés\n",
    "        cropped_triangle = imagen1[y:y + h, x:x + w]\n",
    "\n",
    "        # Creamos una máscara que sea de zeros pero en vez de que se base de otro array le indicamos el Heigh y el Width del triángulo correspondiente\n",
    "        cropped_tr1_mask = np.zeros((h, w), np.uint8)\n",
    "\n",
    "        # Sacamos los puntos en un array de puntos de X e Y que quedaría con la siguiente estructura\n",
    "        # [[X0,Y0],\n",
    "        #  [X1,Y1],\n",
    "        #  [X2,Y2]]\n",
    "        # Siendo la matriz resultante 3 x 2\n",
    "        points = np.array([[pt[0] - x, pt[1] - y] for pt in tr1_pts], np.int32)\n",
    "\n",
    "        # Rellenamos los datos de la máscara creada del Height y el Width con un polígono\n",
    "        cv2.fillConvexPoly(cropped_tr1_mask, points, 255)\n",
    "\n",
    "        # Lo mismo con la mascara de líneas vacía\n",
    "        cv2.fillConvexPoly(lines_space_mask, triangle1, 255)\n",
    "        # endregion\n",
    "\n",
    "        # region Imagen 2 Tratamiento\n",
    "        # Triangulación de la segunda cara con el mismo formato que la anterior\n",
    "        tr2_pts = [land2[idx] for idx in triangle_index]\n",
    "        triangle2 = np.array(tr2_pts, np.int32)\n",
    "\n",
    "        # boundingRect devuelve un conjunto de 4 parametros la coordenada x,y y el width y height del array\n",
    "        rect2 = cv2.boundingRect(triangle2)\n",
    "        x, y, w, h = rect2\n",
    "        cropped_tr2_mask = np.zeros((h, w), np.uint8)\n",
    "\n",
    "        # Sacamos los puntos en un array de puntos de X e Y que quedaría con la siguiente estructura\n",
    "        # [[X0,Y0],\n",
    "        #  [X1,Y1],\n",
    "        #  [X2,Y2]]\n",
    "        # Siendo la matriz resultante 3 x 2\n",
    "        points2 = np.array([[pt[0] - x, pt[1] - y] for pt in tr2_pts], np.int32)\n",
    "        cv2.fillConvexPoly(cropped_tr2_mask, points2, 255)\n",
    "        # endregion\n",
    "\n",
    "        # region Adaptación de la imagen\n",
    "\n",
    "        # Convertimos los puntos calculados de cada imagen en array de numpy para evitar los petes\n",
    "        points = np.float32(points)\n",
    "        points2 = np.float32(points2)\n",
    "\n",
    "        # Nos da un array M con el affine transform de los puntos 1 y los puntos 2\n",
    "        M = cv2.getAffineTransform(points, points2)\n",
    "\n",
    "        # Con el triángulo dado lo transformamos con el M calculado y la máscara  \n",
    "        warped_triangle = cv2.warpAffine(cropped_triangle, M, (w, h))\n",
    "\n",
    "        # Ahora junta el triángulo en la imagen de la máscara\n",
    "        warped_triangle = cv2.bitwise_and(warped_triangle, warped_triangle, mask=cropped_tr2_mask)\n",
    "\n",
    "        # Con las coordenadas Y y X creamos el area de la cara\n",
    "        img2_new_face_rect_area = img2_new_face[y:y + h, x:x + w]\n",
    "\n",
    "        # Sacamos el Threshold de la imagen invertida y tendremos la máscara\n",
    "        _, mask_triangles_designed = cv2.threshold(cv2.cvtColor(img2_new_face_rect_area, cv2.COLOR_BGR2GRAY), 1, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        # El triangulo ahora ya es el deseado\n",
    "        warped_triangle = cv2.bitwise_and(warped_triangle, warped_triangle, mask=mask_triangles_designed)\n",
    "\n",
    "        # Y lo insertamos en la nueva imagen calculada\n",
    "        img2_new_face[y:y + h, x:x + w] = cv2.add(img2_new_face_rect_area, warped_triangle)\n",
    "        # endregion\n",
    "    # endregion\n",
    "\n",
    "    # Ejecutamos la función de NumPy de manera recursiva en el axis=1 para que ejecute de manera equitativa al for\n",
    "    np.apply_along_axis(triangle_f,axis=1,arr=triangles)\n",
    "\n",
    "    # Le añadimos una distorsión a la imagen para eliminar lineas negras\n",
    "    img2_new_face = cv.GaussianBlur(src=img2_new_face, ksize=(5,5), sigmaX=5, sigmaY=5 )\n",
    "    plt.imshow(img2_new_face)\n",
    "    \n",
    "    # Y retornamos\n",
    "    return img2_new_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2)\n",
    "\n",
    "# Obtenemos las dos caras para ver como quedarían adaptadas a sus respectivas imagenes triángulo a triángulo\n",
    "img1_f=get_face(img,img2,landmarks_points,landmarks_points2)\n",
    "img2_f=get_face(img2,img,landmarks_points2,landmarks_points)\n",
    "#axs[0].imshow(img1_f)\n",
    "#axs[1].imshow(img2_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagen_unida(imagen_original,face,landmarks_image):\n",
    "    \"\"\"Une la imagen donde se pondrá la cara con la cara sacada y sus puntos de landmarks\n",
    "\n",
    "    Args:\n",
    "        imagen_original (Array Object Np.Int(X)): Imagen donde se pondrá la cara\n",
    "        face (Array Object Np.Int(X)): La cara sacada anteriormente\n",
    "        landmarks_image (Array Tuple (X,Y)): Coordenadas X e Y de los puntos de orden 0 - len(NORMALIZED)\n",
    "\n",
    "    Returns:\n",
    "        (Array Object Np.Int(X)): Imagen modificada\n",
    "    \"\"\"\n",
    "    convexhull2 = cv2.convexHull(np.array(landmarks_image, np.int32))\n",
    "    img2_gray = cv2.cvtColor(imagen_original, cv2.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv.GaussianBlur(src=img2_gray, ksize=(5,5), sigmaX=5, sigmaY=5)\n",
    "    img2_face_mask = np.zeros_like(img2_gray)\n",
    "    img2_head_mask = cv2.fillConvexPoly(img2_face_mask, convexhull2, 255)\n",
    "    img2_face_mask = cv2.bitwise_not(img2_head_mask)\n",
    "\n",
    "    img2_head_noface = cv2.bitwise_and(imagen_original, imagen_original, mask=img2_face_mask)\n",
    "    result = cv2.add(img2_head_noface, face)\n",
    "\n",
    "    (x, y, w, h) = cv2.boundingRect(convexhull2)\n",
    "    center_face2 = (int((x + x + w) / 2), int((y + y + h) / 2))\n",
    "\n",
    "    seamlessclone = cv2.seamlessClone(result, imagen_original, img2_head_mask, center_face2, cv2.NORMAL_CLONE)\n",
    "\n",
    "    return cv2.cvtColor(seamlessclone,cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final1=imagen_unida(img2,img1_f,landmarks_points2)\n",
    "final2=imagen_unida(img,img2_f,landmarks_points)\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].imshow(final1)\n",
    "axs[1].imshow(final2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagen = img\n",
    "\n",
    "landmark=landmarks_points\n",
    "\n",
    "video = cv.VideoCapture(0)\n",
    "\n",
    "# Especificamos las características del modelo detector de caras\n",
    "with mp_face_mesh.FaceMesh(static_image_mode=False,max_num_faces=1, min_detection_confidence=0.5) as face_mesh:\n",
    "    while(True):\n",
    "\n",
    "        # Recogemos el frame del video actual\n",
    "        ret, frame = video.read()\n",
    "        if ret == True:\n",
    "            frame = cv.flip(frame, 1)\n",
    "\n",
    "            # Procesamiento del frame por el resultado\n",
    "            results = face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            if results.multi_face_landmarks:\n",
    "                for face_landmarks in results.multi_face_landmarks:\n",
    "                    landmarks_points_f = [(int(landmark.x * frame.shape[1]), int(landmark.y * frame.shape[0])) for landmark in face_landmarks.landmark]\n",
    "                try:\n",
    "\n",
    "                    # Con el video actual saca la cara y la une con el resto de nuesra cara actual\n",
    "                    annotated_image=get_face(imagen,frame,landmark,landmarks_points_f)\n",
    "                    final1=imagen_unida(frame,annotated_image,landmarks_points_f)\n",
    "                except:\n",
    "                    final1 = frame\n",
    "                cv.imshow(\"Salida\", cv.cvtColor(final1,cv.COLOR_BGR2RGB))\n",
    "            cv.imshow(\"Cara normal\", cv.cvtColor(frame,cv.COLOR_BGR2RGB))\n",
    "        if ret == False:\n",
    "            video.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "        if cv.waitKey(10) & 0xFF == 27: break\n",
    "    \n",
    "video.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
