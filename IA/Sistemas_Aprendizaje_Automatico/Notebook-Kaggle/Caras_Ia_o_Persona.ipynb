{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "path=str(pathlib.Path().resolve())+\"\\\\Faces\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_dir(dir):\n",
    "    global path\n",
    "    dir = os.path.join(path,dir)\n",
    "    return tf.keras.utils.image_dataset_from_directory(\n",
    "           dir,\n",
    "           labels='inferred',\n",
    "           color_mode=\"rgb\",\n",
    "           seed=42,\n",
    "           batch_size=32,\n",
    "           image_size=(128, 128))\n",
    "\n",
    "train = get_from_dir(\"Train\")\n",
    "test = get_from_dir(\"Test\")\n",
    "val = get_from_dir(\"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train.take(1):\n",
    "    print(\"Etiqueta de la primera imagen:\", labels[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class_names = np.unique(train.class_names)\n",
    "\n",
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "data = list(train.take(n_rows*n_cols))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        # Obtener solo la primera imagen del lote\n",
    "        single_image = data[index][0][0]  # Tomar la primera imagen del primer lote\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(single_image.numpy().astype(\"uint8\"),cmap=\"gray\")  # Convertir a tipo uint8 para imshow\n",
    "        plt.axis('off')\n",
    "        # Convertir a un solo valor antes de usarlo para indexar class_names\n",
    "        label_index = data[index][1][0]\n",
    "        plt.title(class_names[label_index], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# Va hacer 32 Kernels que serán 3X3 es decir\n",
    "# Recogera de cada 3 pixeles el central para la nueva imagen \n",
    "# Podríamos indicar los Strides (1,1) que son las casillas que avanza\n",
    "# Le decimos que sea 28 x 28 y que tenga un canal\n",
    "model.add(layers.Conv2D(32,(3,3),activation=\"relu\", padding='same',input_shape=(128,128,3)))\n",
    "model.add(layers.Conv2D(32,(3,3),activation=\"relu\", padding='same'))\n",
    "\n",
    "# Se va reduciendo la imagen por lo que podemos aumentar el número de filtros, donde la imagen se nos va a la mitad\n",
    "model.add(layers.MaxPooling2D((2,2), strides=(2, 2)))\n",
    "\n",
    "# Lo normal es aumentar el número de filtros en la imagen\n",
    "model.add(layers.Conv2D(64,(3,3),activation=\"relu\", padding='same'))\n",
    "model.add(layers.Conv2D(64,(3,3),activation=\"relu\", padding='same'))\n",
    "model.add(layers.MaxPooling2D((2,2), strides=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(128,(3,3),activation=\"relu\", padding='same'))\n",
    "model.add(layers.Conv2D(128,(3,3),activation=\"relu\", padding='same'))\n",
    "model.add(layers.MaxPooling2D((2,2), strides=(2, 2)))\n",
    "\n",
    "# Aplana la capa actual\n",
    "#model.add(layers.Conv2D(128,(3,3),activation=\"relu\"))\n",
    "#model.add(layers.Conv2D(128,(3,3),activation=\"relu\"))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(128,activation=\"relu\"))\n",
    "model.add(layers.Dense(64,activation=\"relu\"))\n",
    "model.add(layers.Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam',loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#print(gpus)\n",
    "#tf.config.set_visible_devices([], 'CPU') # hide the CPU\n",
    "#tf.config.set_visible_devices(gpus[0], 'GPU') # unhide potentially hidden GPU\n",
    "#tf.config.get_visible_devices()\n",
    "\n",
    "\n",
    "#cpus = tf.config.experimental.list_physical_devices('CPU')\n",
    "#print(cpus)\n",
    "#tf.config.set_visible_devices([], 'GPU')  # hide the GPU\n",
    "#tf.config.set_visible_devices(cpus[0], 'CPU') # unhide potentially hidden CPU\n",
    "#tf.config.get_visible_devices()\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5,restore_best_weights=True)\n",
    "\n",
    "\n",
    "history = model.fit(train,epochs=sys.maxsize,batch_size=32,validation_data=val,callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelo_detector_caras.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = model.predict(test)\n",
    "predicciones = (predicciones >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Obtener las etiquetas verdaderas y las predicciones\n",
    "true_labels = []\n",
    "predictions = []\n",
    "\n",
    "for images, labels in test:\n",
    "    true_labels.extend(labels.numpy())\n",
    "    batch_predictions = model.predict(images) >= 0.5\n",
    "    predictions.extend(batch_predictions.astype(int).flatten())\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
