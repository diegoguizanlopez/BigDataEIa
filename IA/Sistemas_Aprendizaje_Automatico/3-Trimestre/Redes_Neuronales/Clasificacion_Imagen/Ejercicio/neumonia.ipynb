{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de Neumonía con Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "path=str(pathlib.Path().resolve())+\"/assets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtenemos el mapa de bits de la imagen en escala de 128^2 para las dos imagenes en escala de grises por lo que la 3ª dimensión de la imagen será 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import random\n",
    "\n",
    "def get_data(path):\n",
    "    images = []  # Lista para las imágenes\n",
    "    labels = []  # Lista para las etiquetas\n",
    "    dirs = os.listdir(path)\n",
    "    \n",
    "    for dir in dirs:\n",
    "        for img in os.listdir(path+\"/\"+dir):\n",
    "            images.append(cv.cvtColor(cv.resize(cv.imread(path +\"/\"+  dir + \"/\" + img), dsize=(128, 128),interpolation=cv.INTER_AREA),cv.COLOR_BGR2GRAY))\n",
    "            if dir==\"NORMAL\":\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "    \n",
    "    # Barajar las imágenes y las etiquetas de manera sincronizada\n",
    "    combined = list(zip(images, labels))\n",
    "    random.shuffle(combined)\n",
    "    images, labels = zip(*combined)\n",
    "    \n",
    "    print(path + \"/\" + dirs[1])\n",
    "    \n",
    "    # Convertir las listas en arrays NumPy\n",
    "    \n",
    "    return np.array(images),np.array(labels) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutamos en multi hilo la recolección de cada una de las carpetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    f1 = executor.submit(get_data, path+\"train\")\n",
    "    f2 = executor.submit(get_data, path+\"test\")\n",
    "    f3 = executor.submit(get_data, path+\"val\")\n",
    "\n",
    "    train = f1.result()\n",
    "    test = f2.result()\n",
    "    val = f3.result()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenamos cada uno de los valores en X e Y que luego dividiremos en sus respectivos valores con Train-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.concatenate((train[0],test[0],val[0]))\n",
    "y=np.concatenate((train[1],test[1],val[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividimos los datos en Train,test,val, estos los usaremos en la Red neuronal como valores de entrenamiento, test, validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_full, X_test , y_train_full, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train, X_val , y_train, y_val = train_test_split(X_train_full,y_train_full,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos de forma Random imagenes que tienen Normal o Pneumonia de X_train e y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class_names = [\"NORMAL\",\"PNEUMONIA\"]\n",
    "\n",
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(class_names[y_train[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estandarizamos las imagenes dividiendo entre 255 todos los valores de cada uno de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.\n",
    "X_test = X_test / 255.\n",
    "X_val = X_val / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_val,y_val=X_test[:int(len(X_test)/2)],y_test[:int(len(y_test)/2)]\n",
    "#X_test,y_test=X_test[int(len(X_test)/2):],y_test[int(len(y_test)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train=X_train.astype(np.uint8,copy=False)\n",
    "#X_test=X_test.astype(np.uint8,copy=False)\n",
    "#X_val=X_val.astype(np.uint8,copy=False)\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "#(1280, 64, 64, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un modelo de 9 capas\n",
    "- 3 Conv2(32,64,128),(3,3)\n",
    "- 3 MaxPooling2D(2,2)\n",
    "- 1 Flatten()\n",
    "- 2 Dense(\"relu\",\"sigmoid\")(128,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# Va hacer 32 Kernels que serán 3X3 es decir\n",
    "# Recogera de cada 3 pixeles el central para la nueva imagen \n",
    "# Podríamos indicar los Strides (1,1) que son las casillas que avanza\n",
    "# Le decimos que sea 28 x 28 y que tenga un canal\n",
    "model.add(layers.Conv2D(32,(3,3),activation=\"relu\",input_shape=(X.shape[1],X.shape[2],1)))\n",
    "#model.add(layers.Conv2D(32,(3,3),activation=\"relu\"))\n",
    "\n",
    "# Se va reduciendo la imagen por lo que podemos aumentar el número de filtros, donde la imagen se nos va a la mitad\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# Lo normal es aumentar el número de filtros en la imagen\n",
    "model.add(layers.Conv2D(64,(3,3),activation=\"relu\"))\n",
    "#model.add(layers.Conv2D(64,(3,3),activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# Aplana la capa actual\n",
    "model.add(layers.Conv2D(128,(3,3),activation=\"relu\"))\n",
    "#model.add(layers.Conv2D(128,(3,3),activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(128,activation=\"relu\"))\n",
    "model.add(layers.Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, \"model.png\", show_shapes=True,show_dtype=True,show_layer_names=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicamos que usamos el Adam con lr de 0.001, con el binary_crossentropy y la metrica de accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",  optimizer=keras.optimizers.Adam(learning_rate=0.001),   metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo con el EarlyStopping y una paciencia de 10, también indicamos que use CPU ya que disponemos de integrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#print(gpus)\n",
    "#tf.config.set_visible_devices([], 'CPU') # hide the CPU\n",
    "#tf.config.set_visible_devices(gpus[0], 'GPU') # unhide potentially hidden GPU\n",
    "#tf.config.get_visible_devices()\n",
    "\n",
    "\n",
    "cpus = tf.config.experimental.list_physical_devices('CPU')\n",
    "print(cpus)\n",
    "tf.config.set_visible_devices([], 'GPU')  # hide the GPU\n",
    "tf.config.set_visible_devices(cpus[0], 'CPU') # unhide potentially hidden CPU\n",
    "tf.config.get_visible_devices()\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(X_train,y_train,epochs=sys.maxsize,validation_data=(X_val,y_val),callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el modelo para ver su rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)\n",
    "#accuracy: 0.9582 - loss: 0.1282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred_labels = y_test_pred.round(0)\n",
    "y_test_true_labels = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusión para ver como predijo el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test_true_labels, y_test_pred_labels)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.ylabel('Verdadero')\n",
    "plt.xlabel('Predicho')\n",
    "plt.title('Matriz de confusión')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
