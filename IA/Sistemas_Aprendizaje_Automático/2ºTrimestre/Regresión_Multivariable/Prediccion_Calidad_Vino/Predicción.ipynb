{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Manejo de DataSet de vinos para predicción de la calidad**\n",
    "\n",
    "<a href=\"https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009\">**DataSet Kaggle**</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Obtención de datos](#obtención-de-datos)\n",
    "\n",
    "2. [Lectura de datos y analisis de ellos](#lectura-de-datos-y-analisis-de-ellos)\n",
    "    1. [Picos](#picos)\n",
    "     <p></p>\n",
    "\n",
    "3. [Visualización de datos](#visualización-de-datos)\n",
    "    1. [Scatter](#scatter-de-ácido-volátil-ácido-citrico-y-calidad-del-vino)\n",
    "\n",
    "    2. [BoxPlot](#boxplot-de-coorrelaciones)\n",
    "\n",
    "    3. [Mátriz de coorrelación](#matriz-de-correlación-y-mapa-de-calor)\n",
    "    \n",
    "    4. [Scatter Matrix](#scatter-matrix)\n",
    "\n",
    "4. [Experimentación con columnas](#experimentación-con-columnas)\n",
    "\n",
    "5. [Preparación de datos](#preparación-de-datos)\n",
    "    1. [Limpieza](#limpieza)\n",
    "    \n",
    "    2. [División de datos](#división-de-datos)\n",
    "\n",
    "6. [Definición de los modelos](#definición-de-los-modelos)\n",
    "    1. [LINEAL](#lineal)\n",
    "\n",
    "    2. [ÁRBOL DE DECISIONES](#árbol-de-decisiones)\n",
    "\n",
    "    3. [VALIDACIÓN CRUZADA DEL ÁRBOL DE DECISIONES](#validación-cruzada-del-árbol-de-decisiones)\n",
    "\n",
    "    4. [RANDOM FOREST MODELO](#random-forest-modelo)\n",
    "\n",
    "    5. [SVR](#svr)\n",
    "\n",
    "    6. [XGBOOST](#xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Obtención de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargamos el dataset de forma local y cogemos su ruta para leer el .csv y meterlo a un DataFrame de Pandas donde trataremos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "path=str(pathlib.Path().resolve())+\"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "wine = pd.read_csv(path+\"winequality-red.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lectura de datos y analisis de ellos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos los datos y analizamos que tipo de datos son las columnas y vemos cuales son Nulos. Etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:yellow\">ADVERTENCIA</p>Como vemos no tenemos ninguna columna con valores nulos, en caso de tenerlo deberiamos tratarlo en su respectivo tratamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos los picos, donde muchos componen picos normales, pero otros picos son más extraños"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.hist(bins=20,figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualización de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter de ácido volátil, ácido citrico y calidad del vino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos una pequeña relación entre el ácido volatil con el citrico, cuando menos acido cítrico por norma general es mayor el ácido volatil, mientras que si se acerca el vino al pico del ácido volatil, pierde calidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.plot.scatter(y=\"volatile acidity\",x=\"citric acid\",alpha=0.2,c=\"quality\",cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoxPlot de coorrelaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos un BoxPlot de las coorrelaciones de la calidad del vino con las diferentes columnas que ya hay en la propia tabla, esto nos permite eliminar los Ouliers que eliminaremos más adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from Clases.Matplot.BoxPlot import BoxPlot\n",
    "\n",
    "\n",
    "BoxPlot.box_plot(types=wine.columns,by=\"quality\",dataFrame=wine,deepColor=\"deeppink\",faceColor=\"Pink\",color=\"Pink\",ballsColor=\"deeppink\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de correlación y mapa de calor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el mapa de calor de las relaciones podemos los campos que más se relacionan entre ellos y los que son más importantes para calidad así permitiendo descartar columnas no muy importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Clases.Matplot.HeatMap import HeatMap\n",
    "\n",
    "\n",
    "corr_matrix = wine.corr()\n",
    "HeatMap.heat_map(corr_matrix,corr_matrix.columns,corr_matrix,corr_matrix.columns,corr_matrix.columns,cmap=\"YlGn\",figsize=(10,10),weight=\"bold\",textColor=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter matrix de las columnas para ver los pícos de las columnas y diferencias entre relaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "columns = [\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\",\"quality\"]\n",
    "scatter_matrix(wine[columns], figsize=(12,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Experimentación con columnas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso me interesó probar con datos que me parecen que pueden tener relación entre ellos en este caso \n",
    "<li style=\"color:red\">El total del sulfuro con su free sulfur</li>\n",
    "<li style=\"color:red\">El ácido fixed y el cítrico</li>\n",
    "<li style=\"color:green\">El ácido fixed y la densidad</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine['free_sulfur_dioxide_per_total_sulfur_dioxide'] = wine['total sulfur dioxide']/wine['free sulfur dioxide']\n",
    "\n",
    "wine['citric_acid_per_fixed_acidity'] = wine['fixed acidity']/wine['citric acid']\n",
    "\n",
    "wine['density_per_fixed_acidity'] = wine['fixed acidity']/wine['density']\n",
    "\n",
    "wine['acidity'] = wine['fixed acidity'] + wine['volatile acidity'] + wine['citric acid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que dos de estas no salen con buenas relaciones, entonces los descartamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.drop(['citric_acid_per_fixed_acidity',\n",
    "           #'free_sulfur_dioxide_per_total_sulfur_dioxide',\n",
    "           ],axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preparación de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los campos no tienen nulos por lo que no será necesario tratar los valores nulos de estos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función para el tratamiento de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def tratamiento_outliers(columna,x,y):\n",
    "    \"\"\"Min y Max de una columna\n",
    "\n",
    "    Args:\n",
    "        columna (object): Columna a tratar\n",
    "        x (float): Min\n",
    "        y (float): Max\n",
    "\n",
    "    Returns:\n",
    "        List(float): Min y Max\n",
    "    \"\"\"\n",
    "    sorted(columna)\n",
    "    Q1,Q3 = np.percentile(columna,[x,y])\n",
    "    IQR = Q3 - Q1\n",
    "    lower_range = Q1 - (1.5 * IQR)\n",
    "    upper_range = Q3 + (1.5 * IQR)\n",
    "    return lower_range,upper_range\n",
    "\n",
    "def borrar_outliers(df,columns):\n",
    "    \"\"\"Borra los Outliers\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): DataFrame con los datos\n",
    "        columns (X): Columnas\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Nuevo DataFrame con los datos borrados\n",
    "    \"\"\"\n",
    "    for i,value in columns.items():\n",
    "        if df[i].dtype == 'float64':\n",
    "            low,high=tratamiento_outliers(df[i],value[0],value[1])\n",
    "            df.drop(\n",
    "                df[(df[i] > high) | (df[i] < low) ].index , \n",
    "                inplace=True)\n",
    "            #df_filtrado = df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#columnas=[\"quality\",\"alcohol\",\"sulphates\",\"chlorides\",\"residual sugar\",\"citric acid\",\"fixed acidity\"]\n",
    "#columnas = [\"quality\",\"alcohol\",\"sulphates\",\"pH\",\"density\",\"total sulfur dioxide\",\"free sulfur dioxide\",\"chlorides\",\"residual sugar\",\"citric acid\",\"volatile acidity\",\"fixed acidity\"]\n",
    "from matplotlib import axis\n",
    "\n",
    "\n",
    "s = wine['quality']\n",
    "wine.drop('quality',axis=1,inplace=True)\n",
    "columnas = {#'citric acid':[10,90],\n",
    "            'chlorides':[10.5,89.5],\n",
    "            #'density':[17.5,82.5],\n",
    "            #'alcohol':[10,90], \n",
    "            'free_sulfur_dioxide_per_total_sulfur_dioxide':[10,90],\n",
    "            'sulphates':[2,98], \n",
    "            'free sulfur dioxide':[5,95],\n",
    "            }\n",
    "wine=borrar_outliers(wine,columnas)\n",
    "wine['quality'] = s\n",
    "columnas = list(wine.columns)\n",
    "#columnas.remove('residual sugar')\n",
    "#columnas.remove('free sulfur dioxide')\n",
    "#columnas.remove('pH')\n",
    "columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BoxPlot.box_plot(types=columnas,by=\"quality\",dataFrame=wine,deepColor=\"deeppink\",faceColor=\"Pink\",color=\"Pink\",ballsColor=\"deeppink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "\n",
    "#wine['fixed acidity'] = scaler.fit_transform(wine[['fixed acidity']])\n",
    "#wine['volatile acidity'] = scaler.fit_transform(wine[['volatile acidity']])\n",
    "#wine['citric acid'] = scaler.fit_transform(wine[['citric acid']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función para dividir el entrenamiento con un ratio (Ya existe una función que lo hace por si solo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data,test_ratio):\n",
    "    # indices = [i for i in range(len(data))]; indices = np.shuffle(.....)\n",
    "  # NOS DA UNA LSITA BARAJADA\n",
    "  indices = np.random.permutation(len(data))\n",
    "  # LE DECIMOS CUANTO TEST SE USARÁ\n",
    "  lg_test = int(len(data) * test_ratio)\n",
    "  # SE REPARTEN\n",
    "  test_indices = indices[:lg_test]\n",
    "  train_indices = indices[lg_test:]\n",
    "  # Y SE DEVUELVE UNA TABLA DE ENTRENAMIENTO Y OTRA DE TEST\n",
    "  return data.iloc[train_indices], data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "x_train,x_test = split_train_test(wine,0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos las variables x_train y y_train que serán los datos para entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.loc[:,columnas]\n",
    "x_test = x_test.loc[:,columnas]\n",
    "#y_train = dt_train[\"quality\"].copy()\n",
    "#x_train = dt_train.drop([\"quality\"],axis=1)\n",
    "\n",
    "y_train = x_train[\"quality\"].copy()\n",
    "x_train = x_train.drop([\"quality\"],axis=1)\n",
    "\n",
    "y_test = x_test[\"quality\"].copy()\n",
    "x_test = x_test.drop([\"quality\"],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejores X Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_selection import SelectKBest,mutual_info_classif\n",
    "#\n",
    "#print(x_train.shape)\n",
    "#selector = SelectKBest(mutual_info_classif,k=14)\n",
    "#selector.fit(x_train,y_train)\n",
    "#x_train = selector.transform(x_train)\n",
    "#x_test = selector.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estandar Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# Mejora un poco el lineal y otros modelos pero el SVR por mucho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polinomios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "#\n",
    "#\n",
    "#poly = PolynomialFeatures(degree=1)\n",
    "#poly.fit(x_train)\n",
    "#x_train = poly.transform(x_train)\n",
    "#x_test = poly.transform(x_test)\n",
    "#x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Definición de los modelos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINEAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train,y_train)\n",
    "\n",
    "# MÓDELO CREADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_prueba =  x_train[:10]\n",
    "print(\"PREDICCIONES: \",lin_reg.predict(datos_prueba))\n",
    "y_reales = y_train[:10]\n",
    "print(\"Reales: \", list(y_reales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "predicciones = lin_reg.predict(x_test)\n",
    "mse = mean_squared_error(y_test, predicciones)\n",
    "mse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, predicciones)\n",
    "score = r2_score(y_test, predicciones)\n",
    "# No lo realiza tan mal\n",
    "print(f\"mae(ERROR MEDIO ABSOLUTO): {mae}   mse(ERROR CUADRÁTICO): {mse}  score:{score}\")\n",
    "# 0.4341950674596512\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que tiene un Score bastante alto para ser un modelo lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VALIDACIÓN CRUZADA LINEAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "lin_score = cross_val_score(lin_reg, x_train, y_train,\n",
    "                            scoring = \"neg_mean_squared_error\", cv=10)\n",
    "root_lin_score = np.sqrt(-lin_score)\n",
    "print(\"Scores: \", root_lin_score)\n",
    "print(\"Media: \", root_lin_score.mean())\n",
    "print(\"Desviación Std\", root_lin_score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÁRBOL DE DECISIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_prueba =  x_train\n",
    "p = tree_reg.predict(datos_prueba)\n",
    "#print(\"PREDICCIONES: \",p)\n",
    "y_reales = y_train\n",
    "#print(\"Reales: \", list(y_reales))\n",
    "for index,i in enumerate(p):\n",
    "    if i != list(y_reales)[index]:\n",
    "        print(f\"EN LA POSICIÓN {index} ES DIFERENTE: \\nEL REAL: {list(y_reales)[index]} -- LA PREDICCIÓN: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = tree_reg.predict(x_train)\n",
    "mse = mean_squared_error(y_train, predicciones)\n",
    "mse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_train, predicciones)\n",
    "score = r2_score(y_train, predicciones)\n",
    "print(f\"mae: {mae}   rmse: {mse} r2_score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = tree_reg.predict(x_test)\n",
    "mse = mean_squared_error(y_test, predicciones)\n",
    "mse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, predicciones)\n",
    "score = r2_score(y_test, predicciones)\n",
    "print(f\"mae: {mae}   rmse: {mse} r2_score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiene un Score de 1.0 Pero engañoso, en el momento que pongamos un dato fuera del DataSet este fallará"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VALIDACIÓN CRUZADA DEL ÁRBOL DE DECISIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lin_score = cross_val_score(tree_reg, x_train, y_train,\n",
    "                            scoring = \"neg_mean_squared_error\", cv=10)\n",
    "root_lin_score = np.sqrt(-lin_score)\n",
    "print(\"Scores: \", root_lin_score)\n",
    "print(\"Media: \", root_lin_score.mean())\n",
    "print(\"Desviación Std\", root_lin_score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que este modelo tiene bastante buena media en el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST MODELO\n",
    "\n",
    "*<p style=\"color:yellow\">(DE LOS MÁS UTILIZADOS, ÁRBOL QUE FUNCIONA CORRECTAMENTE Y MÁS SIMPLE)</p>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "rf_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = rf_reg.predict(x_test)\n",
    "mse = mean_squared_error(y_test, predicciones)\n",
    "mse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, predicciones)\n",
    "score = r2_score(y_test, predicciones)\n",
    "\n",
    "# DE LOS MAYORES SCORES QUE TIENE -1 - 1\n",
    "print(f\"mae: {mae}   rmse: {mse} r2_score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_prueba =  x_test[:20]\n",
    "p = rf_reg.predict(datos_prueba)\n",
    "print(\"PREDICCIONES: \",p)\n",
    "y_reales = y_test[:20]\n",
    "print(\"Reales: \", list(y_reales))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que las mediciones son más precisas con un Score mucho más alto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDACIÓN DE TIPO CROSS AL RANDOM TREE FOREST\n",
    "\n",
    "rf_score = cross_val_score(rf_reg, x_train, y_train,\n",
    "                            scoring = \"neg_mean_squared_error\", cv=10)\n",
    "root_lin_score = np.sqrt(-rf_score)\n",
    "print(\"RF cross\")\n",
    "print(\"Scores: \", root_lin_score)\n",
    "print(\"Media: \", root_lin_score.mean())\n",
    "print(\"Desviación Std\", root_lin_score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR\n",
    "\n",
    "*<p style=\"color:yellow\">(DE LO MÁS UTILIZADO)</p>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "sv_reg = SVR()\n",
    "\n",
    "sv_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = sv_reg.predict(x_test)\n",
    "mse = mean_squared_error(y_test, predicciones)\n",
    "mse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, predicciones)\n",
    "score = r2_score(y_test, predicciones)\n",
    "print(f\"mae: {mae}   rmse: {mse} r2_score: {score}\")\n",
    "#0.5982260797614003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_prueba =  x_test[:20]\n",
    "p = sv_reg.predict(datos_prueba)\n",
    "print(\"PREDICCIONES: \",p)\n",
    "y_reales = y_test[:20]\n",
    "print(\"Reales: \", list(y_reales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg_score = cross_val_score(sv_reg, x_train, y_train,\n",
    "                            scoring = \"neg_mean_squared_error\", cv=10)\n",
    "root_lin_score = np.sqrt(-svg_score)\n",
    "print(\"SV cross\")\n",
    "print(\"Scores: \", root_lin_score)\n",
    "print(\"Media: \", root_lin_score.mean())\n",
    "print(\"Desviación Std\", root_lin_score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la media es decente y su Score tmb pero hay modelos con mejores resultados como el Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **XGBOOST**\n",
    "\n",
    "*(EL MÁS UTILIZADO ACTUALMENTE Y MUY EXTACTO)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -y -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor(objetive=\"reg:squarederror\")\n",
    "\n",
    "#x_train['quality_cat'] = x_train['quality_cat'].astype(int)\n",
    "xgb_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = xgb_reg.predict(x_test)\n",
    "mse = mean_squared_error(y_test, predicciones)\n",
    "mse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, predicciones)\n",
    "score = r2_score(y_test, predicciones)\n",
    "print(f\"mae: {mae}   rmse: {mse} r2_score: {score}\")\n",
    "#0.5193044214733533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_prueba =  x_test[:20]\n",
    "p = xgb_reg.predict(datos_prueba)\n",
    "print(\"PREDICCIONES: \",p)\n",
    "y_reales = y_test[:20]\n",
    "print(\"Reales: \", list(y_reales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_score = cross_val_score(xgb_reg, x_train, y_train,\n",
    "                            scoring = \"neg_mean_squared_error\", cv=10)\n",
    "root_lin_score = np.sqrt(-xgb_score)\n",
    "print(\"XGB cross\")\n",
    "print(\"Scores: \", root_lin_score)\n",
    "print(\"Media: \", root_lin_score.mean())\n",
    "print(\"Desviación Std\", root_lin_score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que esta es el que mejores resultados dá, dando casi un Score de 1 siendo e máximo, manteniendo una media de casi 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluación del modelo con el set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado más parecido al deseado seria con el Random Forest teniendo un rendimiento bastante alto y acercandose a los datos de test con los que no fue entrenado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
